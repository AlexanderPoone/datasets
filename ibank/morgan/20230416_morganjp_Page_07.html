<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN"
	"http://www.w3.org/TR/1998/REC-html40-19980424/loose.dtd">
<html>
<head><meta http-equiv="content-type" content="text/html; charset=UTF-8">
<style type="text/css">
 table.main {}
 tr.row {}
 td.cell {}
 div.block {}
 div.paragraph {}
 .font0 { font:4pt Arial, sans-serif; }
 .font1 { font:6pt Arial, sans-serif; }
 .font2 { font:7pt Arial, sans-serif; }
 .font3 { font:9pt Arial, sans-serif; }
 .font4 { font:12pt Times New Roman, serif; }

</style>
</head>
<body>
<p><span class="font4">J.P. Morgan</span></p>
<p><span class="font0">Atla Pacific Equity Research</span></p>
<p><span class="font0">16 Apr! 2023</span></p>
<div>
<p><span class="font0">Albeit Krag</span></p>
<p><span class="font0">(880-212725 0« 75</span></p>
<p><span class="font0">albert hunggjpmaiai« com</span></p>
</div><br clear="all">
<p><span class="font1">We arc still in the early stage of Al. with most applications focused on machine learning and Al training. As hyperscalcrs could leverage the same servers to train different algorithms under various time frames, this implies limited volume upsides in the training phase for the same customers. Of note, we estimate the OpcnAI organisation to have 2-3k GPU servers while it only takes several hundred Al servers to train a single model in one month.</span></p>
<p><span class="font1">Besides, training is a cost factor for hypersealers so stringent investment in Al learning is important Io keep their margins stable. But. if there were heightened competition in the existing business areas. Internet sen ice providers could prioritize market shares over profitability and invest heavily on front-end research. For example, we believe Google would be likely to accelerate its investments in search engine related areas to defend against competition from MSFT's GPT-powercd Bing.</span></p>
<p><span class="font1">In the medium to near term, we expect more internet service providers to join Al research competition and drive front-end investments in Al servers for training. In the medium to long term, we believe inference plays a more important role in Al server volume scale. Take ChatGPT-3 as an example in Table 4. The GPU server consumption could grow by multiple times if the number of users or the frequency of queries increases. Besides, lire higher number of parameters in each generation could also increase the FLOPs consumption proportionally. As the rising traction of inference applications will incur meaningful costs, the key watch point is whether hyperscalcrs arc able to monetize the product and support the expansion.</span></p>
<p><span class="font2" style="font-weight:bold;">Table 4: Generative Al running cost • Inference (ChatGPT 3.0)</span></p>
<div>
</div><br clear="all">
<div>
</div><br clear="all">
<div>
</div><br clear="all">
<div>
<p><span class="font0">ercun*</span></p>
<p><span class="font0">Lp apart Item WM'Ml'CW</span></p>
<p><span class="font0">•apart •'«{»•</span></p>
</div><br clear="all">
<div>
<p><span class="font0">1»</span></p>
<p><span class="font0">•X</span></p>
<p><span class="font0">tXCM</span></p>
<p><span class="font0">m »» &quot;X</span></p>
</div><br clear="all">
<div>
<p><span class="font0">in &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;in</span></p>
<p><span class="font0">uM»rr«»»&lt;ti</span></p>
</div><br clear="all">
<div>
<p><span class="font1">ua »»</span></p>
</div><br clear="all">
<p><span class="font0">Soxw j P Morgen Mtmem</span></p>
<p><span class="font2" style="font-weight:bold;">Key assumptions of the exercise:</span></p>
<ul style="list-style:none;"><li>
<p><span class="font1">• &nbsp;&nbsp;&nbsp;Monthly visit times: We assume I3mn daily users in Scenario I.</span></p></li>
<li>
<p><span class="font1">• &nbsp;&nbsp;&nbsp;Words in each query: This include the input words and generated words.</span></p></li>
<li>
<p><span class="font1">• &nbsp;&nbsp;&nbsp;Implied tokens per second: We assume I English word 0.75 token.</span></p></li>
<li>
<p><span class="font1">• &nbsp;&nbsp;&nbsp;A100 computing power: 624 TFl.OPs under FPI6 or INT8 structure.</span></p></li></ul>
<p><span class="font3">This document is being provided for the exclusive use of </span><a href="mailto:anthony.wc.liao@jpmorgan.com"><span class="font3">anthony.wc.liao@jpmorgan.com</span></a><span class="font3"> &amp;&nbsp;clients of J.P. Morgan.</span></p>
</body>
</html>